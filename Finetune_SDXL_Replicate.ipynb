{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to use\n",
        "\n",
        "To run and modify the notebook, in the top left go to file -> make a copy in Drive.\n",
        "\n",
        "Useful shortcuts:\n",
        "- Shift + enter: runs a cell\n",
        "\n",
        "Additional Resources:\n",
        "\n",
        "More in depth fine tuning explanation [here](https://civitai.com/articles/4/make-your-own-loras-easy-and-free)"
      ],
      "metadata": {
        "id": "StqF3MkdMx7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install replicate"
      ],
      "metadata": {
        "id": "pdPQvzUKAg1I",
        "outputId": "d11c1572-4c53-44b8-c444-adf7e3d52302",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-1.0.4-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (24.2)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.10.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (2.27.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.2)\n",
            "Downloading replicate-1.0.4-py3-none-any.whl (48 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: replicate\n",
            "Successfully installed replicate-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Run"
      ],
      "metadata": {
        "id": "oanPSyr530oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning a text to image model\n",
        "\n",
        "The first and most important thing to care about when training a custom image generation model, is the data. If you have a bad dataset that you are trianing on, it does not matter what model or how much compute you throw at the problem, your output model will still not perform the way that you want it to.\n",
        "\n",
        "For image generation, we dont actually need a lot of data to add a new concept or style to the model, as little as 5 images will do, although more is always better, usually datasets are between 20-1000 miages. When selecting images here's what you need to keep in mind:\n",
        "\n",
        "- Avoid low quality images, i.e. blurry or low (<256 px) resolution\n",
        "- Avoid images with weird aspect ratios (anything more than 2:1, ie 1024x512px)\n",
        "- Dont worry about getting 4k or super high resolution images, they will be downscaled to ~1024px per side when training\n",
        "\n",
        "When training a model, you will typically either be training the model to understand a person, or new style. Because of this, you will usually include a trigger word that lets the model know you are trying to evoke that concept. That way the model will keep its previous understanding of concepts while also having a new one added to it. Because we dont want to overwrite existing concepts, the trigger word will be a specific person's name, or a \"custom\" word, i.e. \"Andrew Mead\" or \"tr1gg3r w0rd\"."
      ],
      "metadata": {
        "id": "W6R7hAOH0ZlG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jf0Pnm7hELFB"
      },
      "outputs": [],
      "source": [
        "#@title Setup Replicate\n",
        "\n",
        "#@markdown To get your Replicate API key, go to [Replicate](https://replicate.com/signin?next=/docs) and register. You then find your api key on the [API tokens page](https://replicate.com/account/api-tokens), which you can then paste here.\n",
        "\n",
        "import os\n",
        "import replicate\n",
        "from IPython.display import Image\n",
        "\n",
        "# YOUR REPLICATE API KEY\n",
        "replicate_api_key = \"\" #@param {type: 'string'}\n",
        "\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = replicate_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Run"
      ],
      "metadata": {
        "id": "-fZ2MKZJ35e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = replicate.run(\n",
        "    \"stability-ai/sdxl:7762fd07cf82c948538e41f63f77d685e02b063e37e496e96eefd46c929f9bdc\",\n",
        "    input={\n",
        "        \"width\": 768,\n",
        "        \"height\": 768,\n",
        "        \"prompt\": \"Asian Indian Basketball player 13 year old playing basketball with multiple actions\",\n",
        "        \"refine\": \"expert_ensemble_refiner\",\n",
        "        \"scheduler\": \"K_EULER\",\n",
        "        \"lora_scale\": 0.6,\n",
        "        \"num_outputs\": 1,\n",
        "        \"guidance_scale\": 7.5,\n",
        "        \"apply_watermark\": False,\n",
        "        \"high_noise_frac\": 0.8,\n",
        "        \"negative_prompt\": \"\",\n",
        "        \"prompt_strength\": 0.8,\n",
        "        \"num_inference_steps\": 25\n",
        "    }\n",
        ")\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "ES1DGHT_36xF",
        "outputId": "d0315c72-4d65-4c6d-9845-21ed85a242f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<replicate.helpers.FileOutput object at 0x7f703024cb20>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = output[0].url\n",
        "\n",
        "display(Image(url=image_url))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "id": "cQCqsUnK7ACi",
        "outputId": "9e9f7e89-1983-4dc8-eed8-61a9bca3b6d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://replicate.delivery/xezq/flFKa7RXafqSd0CCsZ7OerVjtA9vFk956rdW4mWHcZenBkIQB/out-0.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create the model repository\n",
        "\n",
        "#@markdown Here we are setting up the repository in replicate where the model will go once we have trained it\n",
        "\n",
        "import replicate\n",
        "from replicate.exceptions import ReplicateError\n",
        "\n",
        "#@markdown You can see your username on replicate in the top left corner.\n",
        "replicate_username = \"sundai-club\" #@param {type: 'string'}\n",
        "#@markdown Name of your fintuned model\n",
        "finetuned_mode_name = \"kanch-sundai\" #@param {type: 'string'}\n",
        "\n",
        "try:\n",
        "  model = replicate.models.create(\n",
        "      owner=replicate_username,\n",
        "      name=finetuned_mode_name,\n",
        "      visibility=\"public\",  # or \"private\" if you prefer\n",
        "      hardware=\"gpu-t4\",  # Replicate will override this for fine-tuned models\n",
        "      description=\"A fine-tuned sdxl model\"\n",
        "  )\n",
        "  print(f\"Model created: {model.name}\")\n",
        "except ReplicateError as e:\n",
        "  if \"already exists\" in e.detail:\n",
        "    print(\"Model already exists, loading it.\")\n",
        "    model = replicate.models.get(f\"{replicate_username}/{finetuned_mode_name}\")\n",
        "  else:\n",
        "    raise e\n",
        "\n",
        "print(f\"Model URL: https://replicate.com/{model.owner}/{model.name}\")"
      ],
      "metadata": {
        "id": "3LukzVaWPRFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6044e66f-8cd1-47ef-8118-af349cf6ade4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model created: kanch-sundai\n",
            "Model URL: https://replicate.com/sundai-club/kanch-sundai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "\n",
        "filename = \"/tanay.zip\"\n",
        "with open(f\"{filename}\", \"rb\") as file_input:\n",
        "        encoded_data = base64.b64encode(file_input.read())\n",
        "\n",
        "\n",
        "encoded_data_str = encoded_data.decode('utf-8')"
      ],
      "metadata": {
        "id": "mF6M9NnkGfco"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train the model\n",
        "\n",
        "#@markdown The dataset needs to be a zip folder, with\n",
        "#dataset_url = \"https://drive.google.com/file/d/1inrIw_ObaIE6laOifwwxyme-Y5uVtniW/view?usp=drive_link\" #@param {type: 'string'}\n",
        "trigger_word = \"tanay\" #@param {type: 'string'}\n",
        "steps = 1000 #@param {type: 'number'}\n",
        "\n",
        "training = replicate.trainings.create(\n",
        "    version=\"stability-ai/sdxl:7762fd07cf82c948538e41f63f77d685e02b063e37e496e96eefd46c929f9bdc\",\n",
        "    input={\n",
        "        \"input_images\": f\"data:application/zip;base64,{encoded_data_str}\",\n",
        "        \"steps\": steps,\n",
        "        \"use_face_detection_instead\": True,\n",
        "        \"token_string\": trigger_word,\n",
        "        \"is_lora\": \"true\"\n",
        "    },\n",
        "    destination=f\"{model.owner}/{model.name}\",\n",
        ")\n",
        "\n",
        "print(f\"Training started: {training.status}\")\n",
        "print(f\"Training URL: https://replicate.com/p/{training.id}\")"
      ],
      "metadata": {
        "id": "ZwloUZKKPSKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9aa2c85-0631-4f4f-8e61-10493bbc9fed"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started: starting\n",
            "Training URL: https://replicate.com/p/fa0kjbbkt9rm80cm71pa3sdsww\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.versions.list()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ml56nkVVvgn",
        "outputId": "fab86384-0e35-463e-8804-3fe1941db1d6"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id='ab48229064407355e46d0b84d2a1ea58c5c62c25b9fa6ae4d75a0ff7da864754' created_at=datetime.datetime(2025, 1, 5, 21, 47, 51, 408673, tzinfo=datetime.timezone.utc) cog_version='0.9.5' openapi_schema={'info': {'title': 'Cog', 'version': '0.1.0'}, 'paths': {'/': {'get': {'summary': 'Root', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Root  Get'}}}, 'description': 'Successful Response'}}, 'operationId': 'root__get'}}, '/shutdown': {'post': {'summary': 'Start Shutdown', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Start Shutdown Shutdown Post'}}}, 'description': 'Successful Response'}}, 'operationId': 'start_shutdown_shutdown_post'}}, '/trainings': {'post': {'summary': 'Train', 'responses': {'200': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TrainingResponse'}}}, 'description': 'Successful Response'}, '422': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}, 'description': 'Validation Error'}}, 'parameters': [{'in': 'header', 'name': 'prefer', 'schema': {'type': 'string', 'title': 'Prefer'}, 'required': False}], 'operationId': 'train_trainings_post', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TrainingRequest'}}}}}}, '/predictions': {'post': {'summary': 'Predict', 'responses': {'200': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PredictionResponse'}}}, 'description': 'Successful Response'}, '422': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}, 'description': 'Validation Error'}}, 'parameters': [{'in': 'header', 'name': 'prefer', 'schema': {'type': 'string', 'title': 'Prefer'}, 'required': False}], 'description': 'Run a single prediction on the model', 'operationId': 'predict_predictions_post', 'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PredictionRequest'}}}}}}, '/health-check': {'get': {'summary': 'Healthcheck', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Healthcheck Health Check Get'}}}, 'description': 'Successful Response'}}, 'operationId': 'healthcheck_health_check_get'}}, '/trainings/{training_id}': {'put': {'summary': 'Train Idempotent', 'responses': {'200': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PredictionResponse'}}}, 'description': 'Successful Response'}, '422': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}, 'description': 'Validation Error'}}, 'parameters': [{'in': 'path', 'name': 'training_id', 'schema': {'type': 'string', 'title': 'Training ID'}, 'required': True}, {'in': 'header', 'name': 'prefer', 'schema': {'type': 'string', 'title': 'Prefer'}, 'required': False}], 'operationId': 'train_idempotent_trainings__training_id__put', 'requestBody': {'content': {'application/json': {'schema': {'allOf': [{'$ref': '#/components/schemas/TrainingRequest'}], 'title': 'Training Request'}}}, 'required': True}}}, '/predictions/{prediction_id}': {'put': {'summary': 'Predict Idempotent', 'responses': {'200': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PredictionResponse'}}}, 'description': 'Successful Response'}, '422': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}, 'description': 'Validation Error'}}, 'parameters': [{'in': 'path', 'name': 'prediction_id', 'schema': {'type': 'string', 'title': 'Prediction ID'}, 'required': True}, {'in': 'header', 'name': 'prefer', 'schema': {'type': 'string', 'title': 'Prefer'}, 'required': False}], 'description': 'Run a single prediction on the model (idempotent creation).', 'operationId': 'predict_idempotent_predictions__prediction_id__put', 'requestBody': {'content': {'application/json': {'schema': {'allOf': [{'$ref': '#/components/schemas/PredictionRequest'}], 'title': 'Prediction Request'}}}, 'required': True}}}, '/trainings/{training_id}/cancel': {'post': {'summary': 'Cancel Training', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Cancel Training Trainings  Training Id  Cancel Post'}}}, 'description': 'Successful Response'}, '422': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}, 'description': 'Validation Error'}}, 'parameters': [{'in': 'path', 'name': 'training_id', 'schema': {'type': 'string', 'title': 'Training ID'}, 'required': True}], 'operationId': 'cancel_training_trainings__training_id__cancel_post'}}, '/predictions/{prediction_id}/cancel': {'post': {'summary': 'Cancel', 'responses': {'200': {'content': {'application/json': {'schema': {'title': 'Response Cancel Predictions  Prediction Id  Cancel Post'}}}, 'description': 'Successful Response'}, '422': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}, 'description': 'Validation Error'}}, 'parameters': [{'in': 'path', 'name': 'prediction_id', 'schema': {'type': 'string', 'title': 'Prediction ID'}, 'required': True}], 'description': 'Cancel a running prediction', 'operationId': 'cancel_predictions__prediction_id__cancel_post'}}}, 'openapi': '3.0.2', 'components': {'schemas': {'Input': {'type': 'object', 'title': 'Input', 'properties': {'mask': {'type': 'string', 'title': 'Mask', 'format': 'uri', 'x-order': 3, 'description': 'Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.'}, 'seed': {'type': 'integer', 'title': 'Seed', 'x-order': 11, 'description': 'Random seed. Leave blank to randomize the seed'}, 'image': {'type': 'string', 'title': 'Image', 'format': 'uri', 'x-order': 2, 'description': 'Input image for img2img or inpaint mode'}, 'width': {'type': 'integer', 'title': 'Width', 'default': 1024, 'x-order': 4, 'description': 'Width of output image'}, 'height': {'type': 'integer', 'title': 'Height', 'default': 1024, 'x-order': 5, 'description': 'Height of output image'}, 'prompt': {'type': 'string', 'title': 'Prompt', 'default': 'An astronaut riding a rainbow unicorn', 'x-order': 0, 'description': 'Input prompt'}, 'refine': {'allOf': [{'$ref': '#/components/schemas/refine'}], 'default': 'no_refiner', 'x-order': 12, 'description': 'Which refine style to use'}, 'scheduler': {'allOf': [{'$ref': '#/components/schemas/scheduler'}], 'default': 'K_EULER', 'x-order': 7, 'description': 'scheduler'}, 'lora_scale': {'type': 'number', 'title': 'Lora Scale', 'default': 0.6, 'maximum': 1, 'minimum': 0, 'x-order': 16, 'description': 'LoRA additive scale. Only applicable on trained models.'}, 'num_outputs': {'type': 'integer', 'title': 'Num Outputs', 'default': 1, 'maximum': 4, 'minimum': 1, 'x-order': 6, 'description': 'Number of images to output.'}, 'refine_steps': {'type': 'integer', 'title': 'Refine Steps', 'x-order': 14, 'description': 'For base_image_refiner, the number of steps to refine, defaults to num_inference_steps'}, 'guidance_scale': {'type': 'number', 'title': 'Guidance Scale', 'default': 7.5, 'maximum': 50, 'minimum': 1, 'x-order': 9, 'description': 'Scale for classifier-free guidance'}, 'apply_watermark': {'type': 'boolean', 'title': 'Apply Watermark', 'default': True, 'x-order': 15, 'description': 'Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking.'}, 'high_noise_frac': {'type': 'number', 'title': 'High Noise Frac', 'default': 0.8, 'maximum': 1, 'minimum': 0, 'x-order': 13, 'description': 'For expert_ensemble_refiner, the fraction of noise to use'}, 'negative_prompt': {'type': 'string', 'title': 'Negative Prompt', 'default': '', 'x-order': 1, 'description': 'Input Negative Prompt'}, 'prompt_strength': {'type': 'number', 'title': 'Prompt Strength', 'default': 0.8, 'maximum': 1, 'minimum': 0, 'x-order': 10, 'description': 'Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image'}, 'replicate_weights': {'type': 'string', 'title': 'Replicate Weights', 'x-order': 17, 'description': 'Replicate LoRA weights to use. Leave blank to use the default weights.'}, 'num_inference_steps': {'type': 'integer', 'title': 'Num Inference Steps', 'default': 50, 'maximum': 500, 'minimum': 1, 'x-order': 8, 'description': 'Number of denoising steps'}, 'disable_safety_checker': {'type': 'boolean', 'title': 'Disable Safety Checker', 'default': False, 'x-order': 18, 'description': 'Disable safety checker for generated images. This feature is only available through the API. See [https://replicate.com/docs/how-does-replicate-work#safety](https://replicate.com/docs/how-does-replicate-work#safety)'}}}, 'Output': {'type': 'array', 'items': {'type': 'string', 'format': 'uri'}, 'title': 'Output'}, 'Status': {'enum': ['starting', 'processing', 'succeeded', 'canceled', 'failed'], 'type': 'string', 'title': 'Status', 'description': 'An enumeration.'}, 'refine': {'enum': ['no_refiner', 'expert_ensemble_refiner', 'base_image_refiner'], 'type': 'string', 'title': 'refine', 'description': 'An enumeration.'}, 'scheduler': {'enum': ['DDIM', 'DPMSolverMultistep', 'HeunDiscrete', 'KarrasDPM', 'K_EULER_ANCESTRAL', 'K_EULER', 'PNDM'], 'type': 'string', 'title': 'scheduler', 'description': 'An enumeration.'}, 'WebhookEvent': {'enum': ['start', 'output', 'logs', 'completed'], 'type': 'string', 'title': 'WebhookEvent', 'description': 'An enumeration.'}, 'lr_scheduler': {'enum': ['constant', 'linear'], 'type': 'string', 'title': 'lr_scheduler', 'description': 'An enumeration.'}, 'TrainingInput': {'type': 'object', 'title': 'TrainingInput', 'required': ['input_images'], 'properties': {'seed': {'type': 'integer', 'title': 'Seed', 'x-order': 1, 'description': 'Random seed for reproducible training. Leave empty to use a random seed'}, 'ti_lr': {'type': 'number', 'title': 'Ti Lr', 'default': 0.0003, 'x-order': 8, 'description': \"Scaling of learning rate for training textual inversion embeddings. Don't alter unless you know what you're doing.\"}, 'is_lora': {'type': 'boolean', 'title': 'Is Lora', 'default': True, 'x-order': 6, 'description': 'Whether to use LoRA training. If set to False, will use Full fine tuning'}, 'lora_lr': {'type': 'number', 'title': 'Lora Lr', 'default': 0.0001, 'x-order': 9, 'description': \"Scaling of learning rate for training LoRA embeddings. Don't alter unless you know what you're doing.\"}, 'verbose': {'type': 'boolean', 'title': 'Verbose', 'default': True, 'x-order': 19, 'description': 'verbose output'}, 'lora_rank': {'type': 'integer', 'title': 'Lora Rank', 'default': 32, 'x-order': 10, 'description': \"Rank of LoRA embeddings. Don't alter unless you know what you're doing.\"}, 'resolution': {'type': 'integer', 'title': 'Resolution', 'default': 768, 'x-order': 2, 'description': 'Square pixel resolution which your images will be resized to for training'}, 'input_images': {'type': 'string', 'title': 'Input Images', 'format': 'uri', 'x-order': 0, 'description': 'A .zip or .tar file containing the image files that will be used for fine-tuning'}, 'lr_scheduler': {'allOf': [{'$ref': '#/components/schemas/lr_scheduler'}], 'default': 'constant', 'x-order': 11, 'description': 'Learning rate scheduler to use for training'}, 'token_string': {'type': 'string', 'title': 'Token String', 'default': 'TOK', 'x-order': 13, 'description': 'A unique string that will be trained to refer to the concept in the input images. Can be anything, but TOK works well'}, 'caption_prefix': {'type': 'string', 'title': 'Caption Prefix', 'default': 'a photo of TOK, ', 'x-order': 14, 'description': \"Text which will be used as prefix during automatic captioning. Must contain the `token_string`. For example, if caption text is 'a photo of TOK', automatic captioning will expand to 'a photo of TOK under a bridge', 'a photo of TOK holding a cup', etc.\"}, 'lr_warmup_steps': {'type': 'integer', 'title': 'Lr Warmup Steps', 'default': 100, 'x-order': 12, 'description': 'Number of warmup steps for lr schedulers with warmups.'}, 'max_train_steps': {'type': 'integer', 'title': 'Max Train Steps', 'default': 1000, 'x-order': 5, 'description': 'Number of individual training steps. Takes precedence over num_train_epochs'}, 'num_train_epochs': {'type': 'integer', 'title': 'Num Train Epochs', 'default': 4000, 'x-order': 4, 'description': 'Number of epochs to loop through your training dataset'}, 'train_batch_size': {'type': 'integer', 'title': 'Train Batch Size', 'default': 4, 'x-order': 3, 'description': 'Batch size (per device) for training'}, 'unet_learning_rate': {'type': 'number', 'title': 'Unet Learning Rate', 'default': 1e-06, 'x-order': 7, 'description': 'Learning rate for the U-Net. We recommend this value to be somewhere between `1e-6` to `1e-5`.'}, 'checkpointing_steps': {'type': 'integer', 'title': 'Checkpointing Steps', 'default': 999999, 'x-order': 20, 'description': \"Number of steps between saving checkpoints. Set to very very high number to disable checkpointing, because you don't need one.\"}, 'clipseg_temperature': {'type': 'number', 'title': 'Clipseg Temperature', 'default': 1, 'x-order': 18, 'description': 'How blurry you want the CLIPSeg mask to be. We recommend this value be something between `0.5` to `1.0`. If you want to have more sharp mask (but thus more errorful), you can decrease this value.'}, 'mask_target_prompts': {'type': 'string', 'title': 'Mask Target Prompts', 'x-order': 15, 'description': 'Prompt that describes part of the image that you will find important. For example, if you are fine-tuning your pet, `photo of a dog` will be a good prompt. Prompt-based masking is used to focus the fine-tuning process on the important/salient parts of the image'}, 'input_images_filetype': {'allOf': [{'$ref': '#/components/schemas/input_images_filetype'}], 'default': 'infer', 'x-order': 21, 'description': 'Filetype of the input images. Can be either `zip` or `tar`. By default its `infer`, and it will be inferred from the ext of input file.'}, 'crop_based_on_salience': {'type': 'boolean', 'title': 'Crop Based On Salience', 'default': True, 'x-order': 16, 'description': 'If you want to crop the image to `target_size` based on the important parts of the image, set this to True. If you want to crop the image based on face detection, set this to False'}, 'use_face_detection_instead': {'type': 'boolean', 'title': 'Use Face Detection Instead', 'default': False, 'x-order': 17, 'description': 'If you want to use face detection instead of CLIPSeg for masking. For face applications, we recommend using this option.'}}}, 'TrainingOutput': {'type': 'object', 'title': 'TrainingOutput', 'required': ['weights'], 'properties': {'weights': {'type': 'string', 'title': 'Weights', 'format': 'uri'}}}, 'TrainingRequest': {'type': 'object', 'title': 'TrainingRequest', 'properties': {'id': {'type': 'string', 'title': 'Id'}, 'input': {'$ref': '#/components/schemas/TrainingInput'}, 'webhook': {'type': 'string', 'title': 'Webhook', 'format': 'uri', 'maxLength': 65536, 'minLength': 1}, 'created_at': {'type': 'string', 'title': 'Created At', 'format': 'date-time'}, 'output_file_prefix': {'type': 'string', 'title': 'Output File Prefix'}, 'webhook_events_filter': {'type': 'array', 'items': {'$ref': '#/components/schemas/WebhookEvent'}, 'default': ['start', 'output', 'logs', 'completed']}}}, 'ValidationError': {'type': 'object', 'title': 'ValidationError', 'required': ['loc', 'msg', 'type'], 'properties': {'loc': {'type': 'array', 'items': {'anyOf': [{'type': 'string'}, {'type': 'integer'}]}, 'title': 'Location'}, 'msg': {'type': 'string', 'title': 'Message'}, 'type': {'type': 'string', 'title': 'Error Type'}}}, 'TrainingResponse': {'type': 'object', 'title': 'TrainingResponse', 'properties': {'id': {'type': 'string', 'title': 'Id'}, 'logs': {'type': 'string', 'title': 'Logs', 'default': ''}, 'error': {'type': 'string', 'title': 'Error'}, 'input': {'$ref': '#/components/schemas/TrainingInput'}, 'output': {'$ref': '#/components/schemas/TrainingOutput'}, 'status': {'$ref': '#/components/schemas/Status'}, 'metrics': {'type': 'object', 'title': 'Metrics'}, 'version': {'type': 'string', 'title': 'Version'}, 'created_at': {'type': 'string', 'title': 'Created At', 'format': 'date-time'}, 'started_at': {'type': 'string', 'title': 'Started At', 'format': 'date-time'}, 'completed_at': {'type': 'string', 'title': 'Completed At', 'format': 'date-time'}}}, 'PredictionRequest': {'type': 'object', 'title': 'PredictionRequest', 'properties': {'id': {'type': 'string', 'title': 'Id'}, 'input': {'$ref': '#/components/schemas/Input'}, 'webhook': {'type': 'string', 'title': 'Webhook', 'format': 'uri', 'maxLength': 65536, 'minLength': 1}, 'created_at': {'type': 'string', 'title': 'Created At', 'format': 'date-time'}, 'output_file_prefix': {'type': 'string', 'title': 'Output File Prefix'}, 'webhook_events_filter': {'type': 'array', 'items': {'$ref': '#/components/schemas/WebhookEvent'}, 'default': ['start', 'output', 'logs', 'completed']}}}, 'PredictionResponse': {'type': 'object', 'title': 'PredictionResponse', 'properties': {'id': {'type': 'string', 'title': 'Id'}, 'logs': {'type': 'string', 'title': 'Logs', 'default': ''}, 'error': {'type': 'string', 'title': 'Error'}, 'input': {'$ref': '#/components/schemas/Input'}, 'output': {'$ref': '#/components/schemas/Output'}, 'status': {'$ref': '#/components/schemas/Status'}, 'metrics': {'type': 'object', 'title': 'Metrics'}, 'version': {'type': 'string', 'title': 'Version'}, 'created_at': {'type': 'string', 'title': 'Created At', 'format': 'date-time'}, 'started_at': {'type': 'string', 'title': 'Started At', 'format': 'date-time'}, 'completed_at': {'type': 'string', 'title': 'Completed At', 'format': 'date-time'}}}, 'HTTPValidationError': {'type': 'object', 'title': 'HTTPValidationError', 'properties': {'detail': {'type': 'array', 'items': {'$ref': '#/components/schemas/ValidationError'}, 'title': 'Detail'}}}, 'input_images_filetype': {'enum': ['zip', 'tar', 'infer'], 'type': 'string', 'title': 'input_images_filetype', 'description': 'An enumeration.'}}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = replicate.run(\n",
        "    \"sundai-club/kanch-sundai:ab48229064407355e46d0b84d2a1ea58c5c62c25b9fa6ae4d75a0ff7da864754\",\n",
        "    input={\n",
        "        \"width\": 768,\n",
        "        \"height\": 768,\n",
        "        \"prompt\": \"13 year old indian asian kid playing basketball\",\n",
        "        \"refine\": \"expert_ensemble_refiner\",\n",
        "        \"scheduler\": \"K_EULER\",\n",
        "        \"lora_scale\": 0.6,\n",
        "        \"num_outputs\": 1,\n",
        "        \"guidance_scale\": 7.5,\n",
        "        \"apply_watermark\": False,\n",
        "        \"high_noise_frac\": 0.8,\n",
        "        \"negative_prompt\": \"\",\n",
        "        \"prompt_strength\": 0.8,\n",
        "        \"num_inference_steps\": 25\n",
        "    }\n",
        ")\n",
        "\n",
        "print(output)\n",
        "image_url = output[0].url\n",
        "display(Image(url=image_url))"
      ],
      "metadata": {
        "id": "dw8XLZCIx8MO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "outputId": "0f9e01c0-4d02-4e6d-de9d-f868720ddce4"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<replicate.helpers.FileOutput object at 0x7f6ff436bfd0>]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://replicate.delivery/xezq/zGvjBfUj6nRAPqIeA1UeOEfhdzvfDsqkqatbnYC5mWewdwiAF/out-0.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vp_7uTZujBXc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}